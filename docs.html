<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Docs | Interactive plots</title>
    <style> body { max-width: 700px; margin: 0 auto; padding-bottom: 100px; } </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

    <p><a href="index.html">Back to the plots</a></p>

    <h1>Documentation</h1>

    <p>
        These plots accompany research that has been presented in several 
        talks. 
    </p>

    <ul>
        <li><a href="https://indico.belle2.org/event/4960/">Joint Lepton/Hadron ID (Jul 29)</a></li>
        <li><a href="https://indico.belle2.org/event/5185/">Joint Lepton/Hadron ID (Sep 14)</a></li>
        <li><a href="https://indico.belle2.org/event/5342/">Physics Performance (Oct 6)</a></li>
    </ul>

    <p>
        There is also an accompanying Python package being built to automate
        the production of plots such as these. The repository hosting the 
        development of this package is 
        <a href="https://stash.desy.de/users/chainje/repos/pidml">here</a>
        on the DESY Stash.
    </p>
    
    <h2>Category</h2>

    <p>
        We separate our plots into a few broad categories which can be selected
        from the 'Category' dropdown menu. These are "General performance", 
        "Detector contributions", and "Likelihood ratios". The general performance
        category includes plots that explore the general PID performance of the 
        system or of a given detector. The detector contributions category 
        features a somewhat deeper dive into the roles played by each detector in 
        the overall performance using our contribution metric. The likelihood 
        ratios section features plots made to study the PID on a deeper level by
        considering the likelihood ratios themselves.
    </p>

    <h3>General performance</h3>

    <p>
        There are five kinds of general performance plots that we give: 
        'confusion', 'efficiency', 'ROC curve', 'AUC score', and 'top wrong
        PID'.
    </p>

    <p>
        <b>Confusion</b> plots show the confusion matrix of the model for the
        specified data. In particular, we use log-likelihood information from
        all six PID detectors to calculate the likelihood ratios and determine
        the predicted identity of the particle.
    </p>

    <p>
        <b>Efficiency</b> plots show the signal efficiency of the particle ID
        system for a given particle type in each \( p, \theta \) bin. One can
        also plot the overall accuracy (over all particle types) in each bin by
        choosing the 'All' option in the particle type dropdown.
    </p>

    <p>
        <b>ROC curve</b> plots give the one-versus-rest ROC curves for each of 
        the particle types. 
    </p>

    <p>
        <b>AUC score</b> plots show the one-versus-rest AUC scores for a given 
        particle type in each \( p, \theta \) bin. One can also plot that
        average AUC score over all particle types in each bin by choosing the
        'All' option in the particle type dropdown.
    </p>

    <p>
        <b>Top wrong PID</b> plots show the most commonly chosen incorrect
        particle type in each \( p, \theta \) bin. These plots are most
        informative when the events are first filtered by true particle type.
    </p>
    
    <h3>Detector contributions</h3>

    <p>
        Detector contribution plots aim to help elucidate the role that each
        detector plays individually in an identification. Specifically, for some
        event with predicted particle type \( h \), we define the contribution
        of detector \( d \) to be 
        \[ \text{contrib}_d = P(h) - P(h)_{\cancel{d}}, \]
        where \( P(h) \) is the likelihood ratio for hypothesis \( h \) and 
        \( P(h)_{\cancel{d}} \) is the same likelihood ratio but calculated
        omitting the log-likelihood data of detector \( d \). Then, of the six
        detectors, the one with the largest contribution is said to take the
        "blame" for the identification, good or bad. <b>Note</b> specifically
        that this is only defined for the hypothesis with the maximum likelihood
        ratio.  We do <i>not</i> consider a detector's contribution to the
        lesser likelihood ratios in these plots.
    </p>

    <p>
        <b>Contribution distribution</b> plots show specifically the
        distribution of these contribution values.
    </p>

    <p>
        <b>Average contribution</b> plots show the average value of the 
        contribution metric achieved by each of the subdetectors on events of
        each particle type.
    </p>

    <p>
        <b>Blame frequency</b> plots show how frequently each detector takes the
        blame for an identification. Specifically, these plots show the fraction
        of times that each detector had the largest contribution to the maximum 
        likelihood ratio.
    </p>

    <p>
        <b>Blame</b> plots show which detector in each \( (p, \theta) \) bin
        takes the blame the most frequently, along with the corresponding
        frequency.
    </p>

    <h3>Likelihood ratios</h3>

    <p>
        These plots are not quite yet available, but are coming soon!
    </p>

    <!-- <p>
    We provide two different views of the likelihood ratios: the distribution of    
    <i>all</i> likelihood ratios for every event or simply the distribution of
    the maximum likelihood ratios. For each, one can filter by whether the event
    was correctly or incorrectly identified. 
    </p>

    <p>
    <b>All event likelihood ratios</b> plots show the distributions of the     
    likelihood ratios for all six supported particle hypotheses. These are
    separated into six subplots by true particle type.
    </p>

    <p>
    <b>Maximum event likelihood ratios</b> plots show the distributions of the     
    maximum likelihood ratio for each event. When filtering by correctly
    identified events, we can see that the plots only show the distributions of
    the likelihood ratios for the correct hypothesis. This makes sense, as the
    event being correctly identified means that the correct hypothesis had the
    largest likelihood ratio.
    </p> -->


    <h2>Options</h2>
    <p>
        For most of the above plots, there are additional options that can be
        selected. These are described below.
    </p>

    <h3>Detector class</h3>
    <p>
        This option allows one to choose whether to use the full ensemble of
        detectors, only a single detector, or all <i>but</i> one detector when
        computing the particle IDs and the plots that result.
    </p>

    <h3>Detector</h3>
    <p>
        If the detector class is chosen to be either single detector or ablation
        (all but one), this option allows one to choose which detector to 
        use/omit.
    </p>

    <h3>Show change from standard?</h3>
    <p>
        For the "ablation test" option on supported plots, we allow one to
        visualize specifically the absolute difference in the plotted values
        from the standard full ensemble values.
    </p>

    <h3>Normalization</h3>
    <p>
        This option allows one to change the normalization of values in 
        confusion matrices. Normalizing by row will give efficiencies relative
        to each true particle type. Normalizing by column will give purities
        relative to each predicted particle type. Not normalizing at all will 
        give the raw number of events in each cell.
    </p>

    <h3>Use bins?</h3>
    <p>
        This option allows you to view the same plot but made using only the
        data in a given \( (p, \theta) \) bin. Checking this box also causes two
        sliders to appear, allowing one to change bins in a very intuitive way.
        In general, when this option is not selected, the quantities shown are 
        computed over all available data in the dataset.
    </p>

    <h3>Correctness</h3>
    <p>
        For many plots, there is an option to filter by correctness. One can
        thus choose to view the plot computed only for events which were
        correctly identified, incorrect identified, or all events regardless.
    </p>

    <h3>Particle type</h3>
    <p>
        For several plots, there is an option to select a particle type. This
        will in general filter the data used to compute the plotted values 
        according to the true particle type of each event.
    </p>

    <h2>Data used for these plots</h2>

    <p>
        The data that were used for these plots are particle gun events,
        simulated using BASF2 release 05-02-06. There are approximately 13
        million such events, comprised of electrons, muons, pions, kaons,
        protons, and deuterons in approximately equal numbers. Data were
        generated with a uniform distribution in momentum from 0.5 to 5 GeV, in
        \( \theta \) from 10 to 170 degrees, and with \( \phi \) varying through
        its entire phase space. For binned studies, we adopt the \( (p, \theta)
        \) bins that are used in Belle II systematics studies. The cutoffs for
        these bins are given by
    </p>

    <ul>
        <li>\( p \): { 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.5 } GeV</li>
        <li>\( \theta \): { 17, 28, 40, 60, 77, 96, 115, 133, 150 } degrees</li>
    </ul>

</body>
</html>
